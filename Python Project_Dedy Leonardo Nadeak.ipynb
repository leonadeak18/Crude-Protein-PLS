{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bb3bb7",
   "metadata": {},
   "source": [
    "## Python Basic\n",
    "### Dedy Leonardo Nadeak, 12332678\n",
    "\n",
    "I am working on developing an efficient partial least square regression (PLSR) model to predict crude protein content in wheat kernel samples using Near Infrared Spectroscopy (NIRS) data. The dataset consists of four sheets: two for calibration purposes and the remaining two for model validation. This datasets is freely available online and was compiled by Wenya Liu, 2016. Here are the three main steps I did:\n",
    "1. Data separation\n",
    "    - Created an argparse input that can separate single workbook based on its sheets.\n",
    "2. Data preprocessing and spectra plotting\n",
    "    - Created an argparse input that can\n",
    "        a. remove sample data that contain null value\n",
    "        b. process preprocessing data, such as Multiplicative scatter correction (MSC), Standard Normal Variate (SNV), first and second derivative.\n",
    "        c. plot all spectra, before and after pretreatment\n",
    "        d. export the plot as an image file\n",
    "3. Build PLSR models and determine the most effective one.\n",
    "    - Create functions that can use to fit a model and plot it.\n",
    "    - By comparing the performance of different models, I determined the most effective one.\n",
    "    \n",
    "Source:\n",
    "Wenya, L. (2016). Wheat kernel dataset: Figshare. Retrieved from https://figshare.com/articles/wheat_kernel_dataset/4252217/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777e3a4",
   "metadata": {},
   "source": [
    "#### Data Import\n",
    "Datasetes is separated based on number of sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c35879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting split_excel_by_sheets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile split_excel_by_sheets.py\n",
    "\"\"\"\n",
    "    Reads an input Excel file and generates separate output CSV files for each sheet.\n",
    "\n",
    "    Actions:\n",
    "        input_excel_path (str): Path to the input Excel file.\n",
    "        output_folder (str): Path to the folder where output CSV files will be saved.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_excel_by_sheets(input_excel_path, output_folder):\n",
    "\n",
    "    # Read the input Excel file into a dictionary of DataFrames (one for each sheet)\n",
    "    excel_file = pd.ExcelFile(input_excel_path)\n",
    "    sheet_data = {sheet_name: excel_file.parse(sheet_name) for sheet_name in excel_file.sheet_names}\n",
    "\n",
    "    # Create separate output CSV files for each sheet\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for sheet_name, df in sheet_data.items():\n",
    "        output_csv_path = os.path.join(output_folder, f\"{sheet_name}.csv\")\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Saved {sheet_name}.csv\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Plotting, Preprocessing and Derivate the NIR Spectra')\n",
    "    parser.add_argument('-i', '--input_excel', type=str, help='Excel file location', required = True)\n",
    "    parser.add_argument('-o', '--out_folder', default = \"output_csv\", type=str, help='Output folder location')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    split_excel_by_sheets(args.input_excel, args.out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4a988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved calibration_X.csv\n",
      "Saved calibration_Y.csv\n",
      "Saved test_X.csv\n",
      "Saved test_Y.csv\n"
     ]
    }
   ],
   "source": [
    "!python split_excel_by_sheets.py -i wheatkernel.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cfa736",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and spectra plotting\n",
    "in NIRS datasets, data preprocessing plays a crucial role. Applying techniques like SNV or MSC helps remove scatter data caused by physical effects, leaving behind only the chemical effects. Additionally, plotting the absorbance data againts their wavelength allows us to evaluate which chemical functional groups are reponsible to the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d298f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Wenya stated that the NIR spectra was recorded at the region 850-1050 nm\n",
    "# Create a variable named wavelength to be used as x-axis in the spectra plotting\n",
    "wavelength = np.array(list(range(850,1050,2)))\n",
    "\n",
    "#export as a csv file\n",
    "np.savetxt('wavelength.csv', wavelength, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5fc99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nir_plot_der.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nir_plot_der.py\n",
    "\"\"\"\n",
    "    This script processes Near-Infrared (NIR) spectra data from a CSV file, performs various preprocessing steps,\n",
    "    and generates plots of the original, preprocessed, and derivative spectra.\n",
    "\n",
    "    Functions:\n",
    "    - remove_na: Removes rows with NA or null values from the dataframe.\n",
    "    - combine_wavelength: Combines wavelength data with the absorbance values if they are in separate CSV files.\n",
    "    - plotting: Plots the spectra data.\n",
    "    - preprocess_msc: Applies Multiplicative Scatter Correction (MSC) preprocessing to the spectra.\n",
    "    - preprocess_snv: Applies Standard Normal Variate (SNV) preprocessing to the spectra.\n",
    "    - derivate: Calculates the derivative of the spectra using Savitzky-Golay smoothing.\n",
    "\n",
    "    Usage:\n",
    "    The script can be run from the command line with various options for preprocessing and plotting.\n",
    "\n",
    "    Arguments:\n",
    "    - -plot: Path to the input CSV file containing the spectra data.\n",
    "    - -w, --wavelength: (Optional) Path to the CSV file containing wavelength data.\n",
    "    - -o, --out_file: (Optional) Path to save the output plot as a PNG file.\n",
    "    - -msc: Apply MSC preprocessing (mutually exclusive with SNV).\n",
    "    - -snv: Apply SNV preprocessing (mutually exclusive with MSC).\n",
    "    - -der: Apply derivative calculation. Choices are 'der1' for 1st derivative and 'der2' for 2nd derivative.\n",
    "\n",
    "    Example usage:\n",
    "    python nir_plot_der.py -plot spectra.csv -w wavelength.csv -o output.png -msc -der der1 der2\n",
    "\n",
    "    The script generates and saves or displays plots of the original, preprocessed, and derivative spectra.\n",
    "\"\"\"\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from chemotools.derivative import SavitzkyGolay\n",
    "\n",
    "#cleaning NA data\n",
    "def remove_na(df):\n",
    "    if df.isnull().values.any():\n",
    "        print(\"NA or null values found. Removing rows with NA or null values\")\n",
    "        df_cleaned = df.dropna()\n",
    "    else:\n",
    "        df_cleaned = df\n",
    "    return df_cleaned\n",
    "\n",
    "#Combine wavelength with the absorbance if csv doesn't contain the wavelength\n",
    "def combine_wavelength(df, wavelength):\n",
    "    wave_data = wavelength.values.flatten()\n",
    "    df_data = df.values\n",
    "    \n",
    "    # Create a DataFrame from df_data\n",
    "    combined_df = pd.DataFrame(df_data, columns=wave_data)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "#Plotting\n",
    "def plotting(df):\n",
    "    x = df.columns.values\n",
    "    y = df.iloc[0:].values\n",
    "    y_transpose = y.T\n",
    "    plt.plot(x, y_transpose)\n",
    "    plt.xlabel(\"Wavelength (nm)\")\n",
    "    plt.ylabel(\"Absorption\") \n",
    "        \n",
    "\n",
    "# Multiplicative scatter correction (MSC) preprocessing\n",
    "def preprocess_msc(df):\n",
    "    # Convert DataFrame to numpy array\n",
    "    y = df.iloc[0:].values\n",
    "    \n",
    "    # Zero mean each spectrum (subtract the mean of each row)\n",
    "    y_centered = y - np.mean(y, axis=1, keepdims=True)\n",
    "    \n",
    "    # Initialize variables\n",
    "    temp = []\n",
    "    y_msc = np.zeros(y.shape)\n",
    "    \n",
    "    # Process each spectrum\n",
    "    for i in range(y_centered.shape[0]):\n",
    "        for j in range(0, y_centered.shape[0], 10):\n",
    "            temp.append(np.mean(y_centered[j:j + 10], axis=0))\n",
    "        \n",
    "        # Compute the mean of the temp array for polyfit\n",
    "        mean_temp = np.mean(temp, axis=0)\n",
    "        fit = np.polyfit(mean_temp, y_centered[i, :], 1)\n",
    "        y_msc[i, :] = (y_centered[i, :] - fit[1]) / fit[0]\n",
    "    \n",
    "    # Convert numpy array back to DataFrame\n",
    "    df_msc = pd.DataFrame(y_msc, columns=df.columns, index=df.index)\n",
    "    \n",
    "    return df_msc\n",
    "\n",
    "#Standard Normal Variate (SNV) preprocessing\n",
    "def preprocess_snv(df):\n",
    "    # Convert DataFrame to numpy array\n",
    "    y = df.iloc[0:].values\n",
    "    \n",
    "    #initialize variable\n",
    "    y_snv = np.zeros_like(df)\n",
    "    \n",
    "    #running the correction\n",
    "    for i in range(y.shape[0]):\n",
    "        y_snv[i,:] = (y[i,:] - np.mean(y[i,:])) / np.std(y[i,:])\n",
    "        \n",
    "    # Convert numpy array back to dataframe\n",
    "    df_snv = pd.DataFrame(y_snv, columns=df.columns, index=df.index)\n",
    "    return df_snv\n",
    "\n",
    "#derivatization\n",
    "def derivate(df, window=15, p_order=2, d_order=1):\n",
    "    sg = SavitzkyGolay(window_size=window, polynomial_order=p_order, derivate_order=d_order)\n",
    "    # Convert DataFrame to numpy array\n",
    "    y = df.iloc[0:].values\n",
    "    der = sg.fit_transform(y)\n",
    "    df_der = pd.DataFrame(der, columns=df.columns, index=df.index)\n",
    "    return df_der\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Plotting, Preprocessing and Derivate the NIR Spectra')\n",
    "    \n",
    "    #Plotting\n",
    "    parser.add_argument('-plot', help=\"Plotting the NIR spectra and output as a jpg\", type=str, required = True)\n",
    "    parser.add_argument('-w','--wavelength', help=\"Reading a csv file that contains wavelength of the spectra\", type=str)\n",
    "    parser.add_argument('-o', '--out_file', type=str, help='Output PNG file for the plot')\n",
    "    \n",
    "    #Mutually exclusive group for MSC and SNV options\n",
    "    group = parser.add_mutually_exclusive_group(required = True)\n",
    "    group.add_argument('-msc', help=\"Input must be a dataframe to run MSC function\", action = 'store_true')\n",
    "    group.add_argument('-snv', help=\"Input must be a dataframe to run SNV function\", action = 'store_true')\n",
    "    \n",
    "    #Derivative can run after choosing SNV or MSC preprocessing\n",
    "    parser.add_argument('-der', nargs='+', help=\"Input must be a dataframe to run derivative function\", choices=['der1', 'der2'])\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "     # Reading the data frame\n",
    "    imported_df = pd.read_csv(args.plot, header=None)\n",
    "    imported_df = remove_na(imported_df)\n",
    "    if args.wavelength:\n",
    "        wavelength = pd.read_csv(args.wavelength, header=None)\n",
    "        df = combine_wavelength(imported_df, wavelength)\n",
    "    else:\n",
    "        df = imported_df\n",
    "    \n",
    "    # Determine number of plots to create\n",
    "    num_plots = 1\n",
    "    if args.msc or args.snv:\n",
    "        num_plots += 1  \n",
    "    if args.der:\n",
    "        num_plots += len(args.der)\n",
    "    \n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plotting\n",
    "    plot_index = 1\n",
    "    \n",
    "    # Plot original data\n",
    "    plt.subplot(1, num_plots, plot_index)\n",
    "    plotting(df)\n",
    "    plt.title('Original Data')\n",
    "    plot_index += 1\n",
    "    \n",
    "    #preprocessing execution\n",
    "    if args.msc:\n",
    "        preprocess_df = preprocess_msc(df)\n",
    "        plt.subplot(1, num_plots, plot_index)\n",
    "        plotting(preprocess_df)\n",
    "        plt.title('MSC Preprocessed Data')\n",
    "        plot_index += 1\n",
    "    elif args.snv:\n",
    "        preprocess_df = preprocess_snv(df)\n",
    "        plt.subplot(1, num_plots, plot_index)\n",
    "        plotting(preprocess_df)\n",
    "        plt.title('SNV Preprocessed Data')\n",
    "        plot_index += 1\n",
    "    \n",
    "    #derivative execution\n",
    "    if args.der:\n",
    "        for der_option in args.der:\n",
    "            if der_option == \"der1\":\n",
    "                der1 = derivate(preprocess_df, d_order=1)\n",
    "                plt.subplot(1, num_plots, plot_index)\n",
    "                plotting(der1)\n",
    "                plt.title('1st Derivative')\n",
    "                plot_index += 1\n",
    "            elif der_option == \"der2\":\n",
    "                der2 = derivate(preprocess_df, d_order=2)\n",
    "                plt.subplot(1, num_plots, plot_index)\n",
    "                plotting(der2)\n",
    "                plt.title('2nd Derivative')\n",
    "                plot_index += 1\n",
    "\n",
    "    # Check if the output location is available\n",
    "    if args.out_file:\n",
    "        #output path\n",
    "        os.makedirs(\"output_plot\", exist_ok=True)\n",
    "        output_plot_path = os.path.join(\"output_plot\", args.out_file)\n",
    "        #export the plot\n",
    "        plt.savefig(output_plot_path)\n",
    "        print(f\"Plot saved as {args.out_file}\")\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "if __name__ == '__main__':\n",
    "    main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014db6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plot.png\n"
     ]
    }
   ],
   "source": [
    "#Plotting and export the output\n",
    "!python nir_plot_der.py -plot output_csv/calibration_X.csv -w wavelength.csv -o plot.png -snv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb703b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting without exporting the output\n",
    "!python nir_plot_der.py -plot output_csv/calibration_X.csv -w wavelength.csv -msc -der der1 der2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f3b61",
   "metadata": {},
   "source": [
    "#### Build PLSR models and determine the most effective one.\n",
    "To construct Partial Least Squares Regression (PLSR) models and identify the most effective one, I utilized two datasets: one for model calibration and another for model evaluation. Specifically, I built six PLSR models, with two of them employing Standard Normal Variate (SNV) and Multiplicative Scatter Correction (MSC) preprocessing without derivatives, while the remaining models incorporated first and second derivatives. The evaluation criteria included coefficient correlation (R²), mean square error (MSE), and the number of components. To enhance efficiency, I restricted the use of ten variables as the maximum number of components in each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f59008d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script is used to create PLS model from the NIR spectra\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "def fitting(cal_x, cal_y, test_x, test_y, n_comp = 2):\n",
    "    model = PLSRegression(n_components = n_comp)\n",
    "    model.fit(cal_x, cal_y)\n",
    "    \n",
    "    pred_y = model.predict(test_x)\n",
    "    mse = metrics.mean_squared_error(test_y, pred_y)\n",
    "    r2 = metrics.r2_score(test_y, pred_y)\n",
    "    \n",
    "    return mse, r2, pred_y\n",
    "\n",
    "def best_fit(cal_x, cal_y, test_x, test_y, n_comp = 2):\n",
    "    #initialize\n",
    "    best_n_comp = 0\n",
    "    best_mse = 0\n",
    "    best_r2 = 0\n",
    "    best_pred_y = []\n",
    "    total_mse = []\n",
    "    total_r2 = []\n",
    "    total_ncomp = []\n",
    "    #iteration for fitting\n",
    "    for i in range(2, n_comp + 1):\n",
    "        mse, r2, pred_y = fitting(cal_x, cal_y, test_x, test_y, n_comp = i)\n",
    "        total_mse.append(mse)\n",
    "        total_r2.append(r2)\n",
    "        total_ncomp.append(i)\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_mse = mse\n",
    "            best_n_comp = i\n",
    "            best_pred_y = pred_y\n",
    "    # MSE plotting\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Mean Square Error\")\n",
    "    plt.plot(total_ncomp, total_mse, marker='.')\n",
    "    plt.scatter([best_n_comp], [best_mse], color='red', zorder=5)  # Highlight the lowest MSE\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xticks(range(2, n_comp + 1))\n",
    "\n",
    "    # R2 to number of component Plotting\n",
    "    plt.subplot(132)\n",
    "    plt.title(f\"$R^2$ Score\")\n",
    "    plt.plot(total_ncomp, total_r2, marker='.')\n",
    "    plt.scatter([best_n_comp], [best_r2], color='red', zorder=5)  # Highlight the highest R2\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel(f\"$R^2$\")\n",
    "    plt.xticks(range(2, n_comp + 1))\n",
    "    \n",
    "    # Prediction vs Test\n",
    "    plt.subplot(133)\n",
    "    plt.title(f\"Prediction Performance (ncomp = {best_n_comp})\")\n",
    "    plt.scatter(test_y, best_pred_y)\n",
    "    plt.xlabel('Reference values')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.text(0.05, 0.95, f'Max $R^2$: {best_r2:.2f}', transform=plt.gca().transAxes,\n",
    "             verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    plt.show()\n",
    "    return best_r2, best_mse, best_n_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d0b4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all data are needed\n",
    "import pandas as pd\n",
    "import nir_plot_der as npd\n",
    "\n",
    "xcal = pd.read_csv(\"output_csv/calibration_X.csv\", header=None)\n",
    "ycal = pd.read_csv(\"output_csv/calibration_Y.csv\", header=None)\n",
    "xtest = pd.read_csv(\"output_csv/test_X.csv\", header=None)\n",
    "ytest = pd.read_csv(\"output_csv/test_Y.csv\", header=None)\n",
    "\n",
    "#preprocessing xcal and xtest\n",
    "xcal_snv_0 = npd.preprocess_snv(xcal).copy()\n",
    "xtest_snv_0 = npd.preprocess_snv(xtest).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best fitting SNV model without derivatives produces an R² value of 0.89 and an MSE of 0.33 with 8 components.\n"
     ]
    }
   ],
   "source": [
    "##Fitting for SNV preprocessing and without derivative.\n",
    "r2_snv_0, mse_snv_0, comp_snv_0 = best_fit(xcal_snv_0, ycal, xtest_snv_0, ytest, n_comp = 10)\n",
    "\n",
    "print(f\"The best fitting SNV model without derivatives produces an R² value of {round(r2_snv_0, 2)} and an MSE of {round(mse_snv_0, 2)} with 8 components.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae927e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for MSC preprocessing and without derivative.\n",
    "xcal_msc_0 = npd.preprocess_msc(xcal).copy()\n",
    "xtest_msc_0 = npd.preprocess_msc(xtest).copy()\n",
    "\n",
    "##Fitting for MSC preprocessing and without derivative.\n",
    "r2_msc_0, mse_msc_0, comp_msc_0 = best_fit(xcal_msc_0, ycal, xtest_msc_0, ytest, n_comp = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1414d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for SNV preprocessing and with first derivative.\n",
    "xcal_snv_1 = npd.derivate(xcal_snv_0, d_order = 1).copy()\n",
    "xtest_snv_1 = npd.derivate(xtest_snv_0, d_order = 1).copy()\n",
    "\n",
    "##Fitting for MSC preprocessing and without derivative.\n",
    "r2_snv_1, mse_snv_1, comp_snv_1 = best_fit(xcal_snv_1, ycal, xtest_snv_1, ytest, n_comp = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc0f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for SNV preprocessing and with second derivative.\n",
    "xcal_snv_2 = npd.derivate(xcal_snv_0, d_order = 2).copy()\n",
    "xtest_snv_2 = npd.derivate(xtest_snv_0, d_order = 2).copy()\n",
    "\n",
    "##Fitting for MSC preprocessing and without derivative.\n",
    "r2_snv_2, mse_snv_2, comp_snv_2 = best_fit(xcal_snv_2, ycal, xtest_snv_2, ytest, n_comp = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b18f498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for MSC preprocessing and with first derivative.\n",
    "xcal_msc_1 = npd.derivate(xcal_msc_0, d_order = 1).copy()\n",
    "xtest_msc_1 = npd.derivate(xtest_msc_0, d_order = 1).copy()\n",
    "\n",
    "##Fitting for MSC preprocessing and without derivative.\n",
    "r2_msc_1, mse_msc_1, comp_msc_1 = best_fit(xcal_msc_1, ycal, xtest_msc_1, ytest, n_comp = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991cb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for MSC preprocessing and with first derivative.\n",
    "xcal_msc_2 = npd.derivate(xcal_msc_0, d_order = 2).copy()\n",
    "xtest_msc_2 = npd.derivate(xtest_msc_0, d_order = 2).copy()\n",
    "\n",
    "##Fitting for MSC preprocessing and without derivative.\n",
    "r2_msc_2, mse_msc_2, comp_msc_2 = best_fit(xcal_msc_2, ycal, xtest_msc_2, ytest, n_comp = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff7b7dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preprocessing  Derivative    R²   MSE  Number of Components\n",
      "0           SNV           0  0.89  0.33                     8\n",
      "1           SNV           1  0.88  0.36                     7\n",
      "2           SNV           2  0.92  0.26                     6\n",
      "3           MSC           0  0.30  2.11                     3\n",
      "4           MSC           1  0.79  0.64                     7\n",
      "5           MSC           2  0.85  0.45                     7\n"
     ]
    }
   ],
   "source": [
    "#Summary of the model\n",
    "import pandas as pd\n",
    "\n",
    "# Create data for the summary table\n",
    "data = {\n",
    "    'Preprocessing': ['SNV', 'SNV', 'SNV', 'MSC', 'MSC', 'MSC'],\n",
    "    'Derivative': [0, 1, 2, 0, 1, 2],\n",
    "    'R²': [round(r2_snv_0, 2), round(r2_snv_1, 2), round(r2_snv_2, 2), round(r2_msc_0, 2), round(r2_msc_1, 2), round(r2_msc_2, 2)],\n",
    "    'MSE': [round(mse_snv_0, 2), round(mse_snv_1, 2), round(mse_snv_2, 2), round(mse_msc_0, 2), round(mse_msc_1, 2), round(mse_msc_2, 2)],\n",
    "    'Number of Components': [round(comp_snv_0, 2), round(comp_snv_1, 2), round(comp_snv_2, 2), round(comp_msc_0, 2), round(comp_msc_1, 2), round(comp_msc_2, 2)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d05891",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The most effective model is the third model with SNV preprocessing and second derivative. This model has the highest R² values and the lowest MSE with only six number of components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
